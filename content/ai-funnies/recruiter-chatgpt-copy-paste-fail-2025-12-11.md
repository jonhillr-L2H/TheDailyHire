---
title: "Recruiter Copy-Pastes ChatGPT Response Including 'As an AI Language Model...' into LinkedIn InMail to Senior Engineer"
author: "Stan 'The Funny Man' Fisher"
date: "December 11, 2025"
category: "ai-funnies"
tags: ["recruiting fails", "AI mistakes", "LinkedIn InMail", "copy-paste disasters"]
---

A recruiter sent a personalized LinkedIn InMail to a senior software engineer that opened with genuine interest in the candidate's background, transitioned into compelling role details, and concluded with "As an AI language model, I don't have personal opinions, but I can provide information about..." followed by three more paragraphs of obviously AI-generated content that the recruiter forgot to edit out before hitting send.

The engineer screenshot the message, posted it with the caption "When your recruiter lets ChatGPT do the work but forgets to remove the AI's signature," and watched it get 50,000 likes from people who were absolutely not surprised this happened.

## When Copy-Paste Goes Horribly, Predictably Wrong

Reports from workplace forums indicate the recruiter was sourcing for a machine learning engineer role and decided to use ChatGPT to help personalize outreach at scale. Smart efficiency move. The problem allegedly arose when they copied ChatGPT's suggested message directly into LinkedIn without reading it through first. Less smart.

According to the engineer's post, the message started fine: "Hi David, I noticed your work on reinforcement learning models at TechCorp and thought you might be interested in a senior ML engineer role at our company." Normal recruiting outreach. Then it allegedly continued with role details that sounded genuine and relevant.

The issue came in paragraph three, where the message apparently shifted to: "As an AI language model, I don't have personal opinions, but I can provide information about why this role might be a good fit based on your background. Machine learning positions at mid-sized companies often offer more hands-on technical work compared to larger enterprises where roles can become specialized."

David, the recipient, allegedly read this twice to make sure he was seeing what he thought he was seeing. Then he screenshot it. Then he posted it. Then the internet had a field day.

## The Message That Keeps on Giving

Reports suggest the full InMail was even better because the recruiter apparently asked ChatGPT multiple questions and pasted all the responses into one message without separating them. The message allegedly included:

"As an AI language model, I should clarify that compensation discussions typically happen later in the interview process, but I can explain that salary ranges for this role..."

And later: "I don't have access to real-time data about this specific company, but based on general industry knowledge, startups in this space typically offer..."

According to David's post, the message concluded with "Let me know if you'd like to schedule a call to discuss further! As an AI language model, I want to emphasize that interview decisions are made by the hiring team." David allegedly replied: "Hi! As a human engineer, I want to emphasize that this message was clearly written by ChatGPT and you forgot to edit it. Maybe schedule some time with 'the hiring team' to learn how to use AI tools more effectively?"

The recruiter reportedly did not respond.

## The Comments Section Went Off

Reports indicate David's LinkedIn post attracted hundreds of comments from other engineers, recruiters, and people who have received similarly obvious AI-generated outreach. Some highlights allegedly included:

"I got one last month that included 'Here are 5 reasons why you might be interested in this role:' and then just had numbered placeholders like '[reason 1]' and '[reason 2]' because the recruiter forgot to fill them in."

"Mine ended with 'Is there anything else I can help you with?' like the recruiter was asking ChatGPT a follow-up question and pasted that too."

"I received an InMail where the recruiter asked ChatGPT 'how do I make this sound more personal' and pasted both the question AND ChatGPT's suggestions for making it sound more personal instead of just implementing the suggestions."

One recruiter allegedly commented: "As a recruiter who uses AI tools responsibly, this is embarrassing for all of us. READ YOUR MESSAGES BEFORE SENDING THEM. It takes 30 seconds. If you can't be bothered to read what you're sending, why would candidates bother reading it?"

## The Recruiter's Company Responds

According to tech blog coverage, David's post got enough visibility that people identified the recruiting agency involved. The agency allegedly posted a response on LinkedIn: "We're aware of the message sent to David and have addressed this internally. We use AI tools to enhance efficiency but require all outreach to be reviewed and personalized by our recruiters before sending. This was a training failure and we apologize for the experience."

Reports suggest the comments on that post were not kind. One person allegedly replied: "So your internal process is 'use AI to write messages but maybe read them first' and somehow this still happened? Impressive quality control." Another commented: "I appreciate the honesty about using AI tools but maybe the training should focus on 'copy-paste is not personalization.'"

The agency reportedly stopped responding to comments after someone pointed out that their "addressed this internally" response also sounded AI-generated.

## Other Recruiters' Horror Stories

According to discussions in recruiting communities, this incident apparently triggered confessions from other recruiters about their own AI-assisted outreach disasters:

"I used ChatGPT to write follow-up emails and accidentally sent one that included my prompt: 'Write a follow-up email to a candidate who hasn't responded, make it sound urgent but not desperate.' The candidate replied 'Sounds pretty desperate to me.'"

"I asked ChatGPT to make my LinkedIn message 'more casual and friendly' and it suggested including emojis. I copy-pasted without reading and sent a message about a C-suite executive role that was just covered in smiley faces and thumbs-up emojis. The candidate asked if I was having a stroke."

"I used AI to personalize 50 outreach messages at once and didn't realize ChatGPT had kept the same opening line for all of them: 'I was impressed by your unique background and specific achievements.' Fifteen candidates compared notes and realized I sent them identical 'personalized' messages. They started a group chat to mock me."

One recruiting leader allegedly posted: "If you're going to use AI for outreach, at minimum: 1) Read what you're sending, 2) Remove obvious AI markers like 'as an AI language model,' 3) Actually personalize beyond just changing the name, 4) Consider whether you'd want to receive this message. It's not hard."

## David's Follow-Up

Reports indicate David posted an update after his original message went viral: "Update: The recruiter reached out to apologize and explain they were under pressure to send high volumes of outreach and got sloppy. I appreciate the apology. I'm not mad at recruiters using AI tools—I literally build AI systems for a living. I'm annoyed by lazy copy-pasting that wastes everyone's time."

He allegedly continued: "If you're going to use ChatGPT to help with recruiting outreach, great! It's a tool. But treating it like a magic button that removes the need to think is how you end up sending messages that say 'as an AI language model' to actual humans who will absolutely screenshot and mock you."

David also reportedly added: "Three other recruiters have now reached out about the same role at the same company using clearly AI-generated messages that at least don't say 'as an AI language model' so I guess we're making progress? Still not interested in the role though."

## The Broader Problem

According to recruiting industry observers, this incident highlights a growing issue: recruiters using AI to increase outreach volume without maintaining quality, resulting in messages that are technically personalized (name is correct, company is relevant) but obviously templated and often riddled with editing failures.

One talent acquisition leader posted on LinkedIn: "AI can help you scale outreach, but it can't scale genuine relationship building. If your process is 'AI generates message → copy-paste → send without reading,' you're not recruiting, you're spamming with extra steps. Candidates can tell. They will mock you. You will become a viral LinkedIn screenshot."

A recruiter replied: "But if we don't send high volumes, we won't hit our metrics!" The TA leader allegedly responded: "Maybe your metrics are measuring the wrong things if they incentivize sending garbage at scale over quality outreach that actually engages candidates."

## The Technical Irony

Multiple people pointed out the hilarious irony that this happened when recruiting a machine learning engineer—someone who builds AI systems and definitely knows what AI-generated text looks like. One comment allegedly read: "Trying to hide AI-written outreach from an ML engineer is like trying to hide a forgery from an art expert. They know. They immediately know. And they're going to be insulted you thought they wouldn't notice."

David reportedly responded: "I actually thought it was funny more than insulting. Like, if you're going to use AI to recruit AI engineers, at least do it competently. We're not anti-AI, we're anti-lazy."

## The Training Gap

Reports suggest several recruiting leaders used this incident as a teaching moment for their teams. One allegedly sent company-wide guidance: "If you use AI tools for candidate outreach: 1) Generate the message, 2) Read it entirely, 3) Remove AI markers and placeholders, 4) Add genuine personalization, 5) Read it again, 6) Ask yourself if you'd respond to this message, 7) THEN send it. If you can't commit to those steps, write it yourself."

Another recruiting manager reportedly told their team: "AI is a drafting tool, not a publishing tool. It helps you start, not finish. If you copy-paste AI output directly into candidate communications without editing, you're using the tool wrong and embarrassing yourself publicly."

## The Candidate Response

According to follow-up discussions, David did eventually receive human-written outreach about the role that was thoughtful, relevant, and clearly written by someone who understood his background. He agreed to an exploratory call. It was not with the recruiter who sent the ChatGPT message.

The new recruiter allegedly opened the call with: "I want to acknowledge that you received some questionable outreach about this role previously. I've actually read your profile and papers, and I promise this conversation will be human-to-human." David reportedly laughed and said that was the best opening he'd heard in a recruiting call this year.

## The Lesson

The moral here is devastatingly simple: If you use AI to help write anything—recruiting messages, emails, whatever—READ IT before sending it. Remove the parts that say "as an AI language model." Remove placeholders. Make sure it sounds like something a human would actually write.

If you can't be bothered to read what you're sending, you shouldn't be sending it. And if you send it anyway, you will become a screenshot, and people will laugh at you, and other recruiters will use your mistake as a cautionary tale in training sessions.

AI tools are great. Lazy copy-pasting is not. The difference is about 30 seconds of reading what you're about to send. Apparently that's too much to ask for some people, but then again, those people probably deserve to be LinkedIn viral examples of what not to do.

David's final comment on his post allegedly read: "I hope this recruiter learned something. I certainly learned to screenshot everything immediately because apparently career content writes itself when recruiters don't read their AI output."

Read your messages, people. Especially if you asked a robot to write them for you. This should not be difficult, and yet here we are.
