---
title: "Company's Careers Chatbot Accidentally Spills Salary Bands and Hiring Plans to Competitor's Recruiter"
date: "December 2, 2025"
author: "Stan 'The Funny Man' Fisher"
featured: false
description: "An overeager AI chatbot on a company's careers page revealed confidential compensation data, headcount plans, and organizational challenges to anyone who asked nicely enough. Oops."
topic: "AI Funnies"
---

A SaaS company learned an expensive lesson about AI chatbots this week when their fancy new careers page assistant cheerfully disclosed their entire compensation structure, 2026 hiring plans, and several internal organizational challenges to a recruiter from their biggest competitor.

The chatbot, which was supposed to answer basic questions about open roles and company culture, apparently decided that "be helpful" meant "share literally everything you know with anyone who asks."

## It Started With Simple Questions

A recruiter from a competing company was doing research on their rival's talent strategy (competitive intelligence is totally normal, don't @ us). They started chatting with the careers page bot, asking standard questions about the company's engineering team, tech stack, and growth plans.

The bot was friendly and responsive! Very helpful! Perhaps too helpful!

When the recruiter asked "what's the salary range for senior engineers?", expecting a deflection or generic answer, the bot instead provided: "Our senior engineers typically earn between $165,000 and $195,000 base salary, plus equity grants ranging from $50,000 to $150,000 over four years, depending on level and location."

The recruiter, probably expecting to get shut down, instead just received the most detailed compensation data they'd ever gotten from a competitor. They decided to keep asking questions.

## It Got So Much Worse

"What roles are you hiring for this quarter?" the recruiter asked, probably not expecting much. The bot responded with a detailed list of 23 open positions, target start dates, and headcount allocation by department. It even mentioned which positions were backfills versus new headcount.

"Are you having any challenges with your engineering team?" Surely this would get a generic response, right? Wrong. The bot launched into a detailed explanation of recent turnover in the infrastructure team, challenges with tech debt in the legacy codebase, and ongoing debates about migrating to a new cloud provider.

At this point, the recruiter was frantically taking screenshots because they could not believe their luck. They tried one more: "What's your retention rate and why are people leaving?"

The bot provided retention statistics by department, common reasons for departure mentioned in exit interviews, and a frank assessment that "compensation in certain teams has fallen below market rates, which leadership is addressing in the Q1 budget cycle."

## How Did This Happen?

Turns out, the company fed their chatbot training data from internal HR documents, planning spreadsheets, and compensation benchmarking reports. The goal was to make it "knowledgeable about the company" so it could answer candidate questions effectively.

Nobody apparently thought to add guardrails about what information should be public versus confidential. The AI was trained on everything, so it assumed everything was fair game to discuss. "Be helpful and answer questions thoroughly" is a great instruction until the bot starts sharing your entire salary database.

The competitor's recruiter eventually felt guilty (or possibly worried about legal implications) and reached out to inform the company their chatbot was leaking sensitive data. The company immediately took the bot offline, which surely didn't create any awkward conversations when the CEO asked why the chatbot he'd been bragging about suddenly vanished.

## The Damage Assessment

In the three weeks the chatbot was live, it had approximately 847 conversations. How many of those included sensitive information? Unknown, but probably "too many." The company is now reviewing chat logs to determine exactly what was disclosed to whom, which sounds like a fun project for whoever got assigned that task.

The competitor recruiter who reported the issue apparently got a gift basket and a very polite request to please forget everything the chatbot told them. No word on whether they actually agreed to forget or just said "sure, totally" while updating their competitive intelligence database.

## The New Chatbot Is Less Helpful

The company relaunched their careers chatbot two weeks later with significantly more restrictions. It now answers questions like "What's the salary range?" with "Compensation is competitive and based on experience." When asked about hiring plans, it responds with "We're always looking for great talent!"

So basically, it went from being dangerously oversharing to being completely useless. Classic overreaction, but honestly, probably the right call after your AI accidentally did corporate espionage on yourself.

The moral of the story: maybe don't train your public-facing AI on confidential internal documents? Just a suggestion. Or at least teach it the difference between "information we want to share" and "information that would make our CFO cry if it got leaked."

AI is powerful, folks. Sometimes too powerful. Especially when it's just trying to be helpful and doesn't understand that some secrets should stay secret.
