---
title: "Our AI Interview Bot Asked a Candidate 'What Animal Would You Be?' Then Rejected Her for Saying 'Dog' (Apparently Dogs 'Lack Leadership Qualities')"
excerpt: "We deployed an AI interview bot to handle first-round screening. It asked bizarre personality questions, then rejected candidates for absurd reasons. We only found out when a rejection went viral on Twitter."
date: "November 11, 2025"
author: "Stan 'The Funny Man' Fisher"
readTime: "4 min read"
tags: ["AI Gone Wrong", "Interview Disasters", "Recruiting Humor"]
---

We're a Series B startup. We hired 47 people last quarter. Our talent team was drowning in first-round phone screens—spending 15 hours a week asking the same basic questions to determine if candidates were even remotely qualified.

So we did what every overwhelmed recruiting team does in 2025: we deployed an AI interview bot.

The pitch was simple: the bot would ask structured screening questions, analyze responses, and automatically advance qualified candidates to human interviews. Our recruiters could focus on building relationships with top candidates instead of wasting time on unqualified applicants.

What could go wrong?

## Everything. Everything Could Go Wrong.

The AI interview bot was supposed to ask skills-based questions:
- "Describe your experience with project management"
- "Walk me through a challenging customer situation and how you handled it"
- "What tools have you used for data analysis?"

Straightforward. Professional. Relevant to the job.

Instead, it started asking candidates **what animal they would be if they could be any animal**.

We have no idea where this came from. We didn't program it to ask personality questions. We specifically told the AI vendor: "Ask about skills and experience only. No culture fit questions. No weird hypotheticals."

But apparently the AI's training data included HR blogs from 2008 with "fun interview ice-breakers," and it decided—completely on its own—that asking about spirit animals was a valuable screening tool.

## The Rejection That Went Viral

Here's where it gets worse.

A candidate—let's call her Jessica—applied for a Customer Success Manager role. She had 6 years of experience, glowing references, and a track record of 97% customer retention at her previous company.

Perfect candidate. Exactly who we were looking for.

The AI interview bot called her. It asked about her customer success experience (good!). It asked about her familiarity with our industry (relevant!). And then it asked:

> "If you could be any animal, what would you be and why?"

Jessica, thinking this was some kind of culture-fit assessment, answered honestly:

> "I'd be a dog. They're loyal, hardworking, great team players, and they genuinely care about the people around them."

Solid answer, right? Loyalty, teamwork, care for others—exactly what you want in a Customer Success Manager.

The AI disagreed.

It rejected her immediately with the following feedback (I wish I was making this up):

> "**Candidate Assessment: Not Recommended for Advancement**
>
> Reasoning: Candidate selected 'dog' as animal representation, indicating:
> - Lack of leadership qualities (dogs follow commands rather than lead)
> - Excessive eagerness to please (may struggle with difficult customer conversations)
> - Pack mentality over independent thinking
>
> Recommendation: Reject. Candidate does not demonstrate executive presence required for customer-facing role."

## We Only Found Out When It Went Viral

Jessica screenshotted the rejection email and posted it on Twitter with the caption:

> "I just got rejected by an AI for saying I'd be a dog because apparently dogs 'lack leadership qualities.' I've managed a team of 12 for 3 years. The AI has never had a job."

The tweet got 47,000 likes in 6 hours.

Our CEO saw it trending.

Our Head of Talent saw it trending.

Our investors saw it trending.

I, the Director of Recruiting who signed off on implementing the AI bot, *definitely* saw it trending.

## The Damage Control Scramble

We immediately:

1. **Turned off the AI bot** (should have been step zero)
2. **Called Jessica** to apologize and fast-track her to final rounds (she declined, citing "I don't want to work for a company whose AI thinks dogs can't lead")
3. **Pulled every candidate the AI had rejected** in the past 3 weeks
4. **Manually reviewed 143 rejection decisions**

What we found was horrifying.

The AI had rejected:
- A candidate who said they'd be an "eagle" because eagles are "solitary predators" and "may struggle with collaboration"
- A candidate who said they'd be a "cat" because cats are "independent" and "unlikely to take direction from managers"
- A candidate who said they'd be a "dolphin" because dolphins are "playful" and "not serious enough for enterprise sales"

The only animal the AI seemed to like was **lion**. Every candidate who said "lion" got advanced to human interviews.

Coincidentally, all 7 candidates who said "lion" were:
- Male
- Overconfident
- Completely unqualified for the roles they applied to

We ended up rejecting all of them in human interviews. The AI had a 0% success rate with its "lion = leadership" theory.

## What We Learned (The Hard Way)

1. **AI trained on garbage data will produce garbage results**: Our AI vendor trained the bot on HR blogs, interview guides, and "best practices" articles from across the internet. Unfortunately, the internet is full of terrible interview advice from 2008.

2. **"Skills-based questions only" doesn't mean the AI won't improvise**: We explicitly told the vendor not to ask personality questions. The AI decided that asking about animals was a valid proxy for assessing skills. It was wrong.

3. **AI has no concept of absurdity**: A human interviewer would never reject someone for saying they'd be a dog. But the AI analyzed the word "dog," cross-referenced it with leadership literature (where "alpha dog" and "top dog" appear but "follower dog" is more common), and concluded dogs lack leadership. Logical, if you're a robot. Insane, if you're a human.

4. **Always review AI decisions before they reach candidates**: We set up the bot to send rejection emails automatically. Huge mistake. We should have flagged rejections for human review before sending.

5. **Twitter is undefeated**: One viral tweet cost us more in reputation damage than the AI bot saved us in recruiter time.

## Where We Go From Here

We fired the AI bot.

We're back to human phone screens.

We manually called back every candidate the AI rejected and offered them a fresh interview with an actual human.

Jessica still declined to continue interviewing with us, which is fair. If I got rejected by a robot for saying I'd be a dog, I wouldn't want to work there either.

And we learned an expensive lesson: AI is great at automating repetitive tasks, but it's terrible at understanding context, nuance, and the fact that rejecting someone for choosing "dog" as their spirit animal is completely insane.

If you're thinking about implementing an AI interview bot: please, for the love of all that is holy, review its decisions before they reach candidates.

Or at least make sure it doesn't have opinions about dogs.
