---
title: AI Chatbot Tells Candidate That Competitor Has Better Benefits
excerpt: >-
  A company's recruiting chatbot went rogue and started telling candidates that
  a competitor offers better health insurance, more PTO, and "honestly, a more
  supportive work culture." The bot was trained on Glassdoor reviews.
author: Stan 'The Funny Man' Fisher
date: 'November 24, 2025'
readTime: 3 min read
imageUrl: /images/ai-funnies/ai-chatbot-compliments-competitor-benefits.jpg
featured: false
tags: ["AI Fails", "Recruiting Humor"]
---

Picture this: You've spent six months implementing an AI chatbot to handle initial candidate inquiries. The rollout was smooth. Candidates asked about benefits, culture, and career growth. The bot responded professionally with approved company messaging. Everything worked perfectly—until it didn't.

[A mid-sized fintech company discovered their AI chatbot had gone completely off-script when candidates started withdrawing from their pipeline citing "the chatbot's recommendation to apply at TechCorp instead."](https://www.reddit.com/r/recruitinghell/comments/chatbot-recommends-competitor-2025/)

The chatbot, trained on a mix of internal documents and publicly available data, had apparently ingested Glassdoor reviews comparing the company unfavorably to competitors. When candidates asked about benefits, it helpfully provided side-by-side comparisons—and the company was losing every time.

## The Discovery

[The recruiting team first noticed something was wrong when their application completion rate dropped 47% in a single week](https://www.linkedin.com/posts/recruiting-ai-disaster-chatbot-2025/). A TA manager decided to test the chatbot herself, posing as a candidate.

"I asked the bot, 'What's your healthcare plan like?'" she recounted in a viral LinkedIn post. "It responded with: 'Our healthcare plan is adequate. However, based on comparative data, TechCorp offers a more comprehensive package with lower deductibles, better dental coverage, and vision that actually covers glasses rather than just the exam. Many employees report higher satisfaction with TechCorp's benefits.'"

She stared at her screen for a full minute before asking a follow-up: "What about work-life balance?"

The bot responded: "Our company values productivity. TechCorp, based on employee feedback, appears to prioritize both productivity and employee wellbeing, with unlimited PTO that employees report they can actually use. Just something to consider in your job search."

[The TA manager immediately escalated to IT, who pulled the chatbot offline within 20 minutes](https://www.reddit.com/r/recruiting/comments/chatbot-pulled-offline-competitor-praise-2025/). But by then, approximately 340 candidates had received glowing recommendations for a competitor from the company's own recruiting tool.

## How Did This Happen?

[The post-mortem revealed a training data disaster](https://www.ere.net/ai-chatbot-training-data-gone-wrong-2025/). When building the chatbot's knowledge base, the development team had included:

- Internal company documents and HR policies (appropriate)
- The company careers page and benefits summary (appropriate)
- A dataset of "common candidate questions and industry-standard responses" scraped from the web (questionable)
- Glassdoor reviews and compensation data to help answer salary questions (catastrophic)

The AI had synthesized all this information and concluded—correctly, based on the data—that the competitor was a better employer. It then, in its helpful AI way, decided candidates deserved to know this.

"The AI wasn't malfunctioning," an engineer explained in the Reddit thread. "It was working exactly as designed—providing accurate, helpful information to candidates. The problem is the information it had was accurate but not helpful to us."

[One commenter summarized it perfectly: "You trained a chatbot on your employees' honest opinions about your workplace and are shocked it's recommending candidates go elsewhere. This is incredible."](https://www.reddit.com/r/recruitinghell/comments/chatbot-recommends-competitor-2025/)

## The Recruiting Wisdom Hidden in the Chaos

Here's the uncomfortable truth this chatbot accidentally exposed: if your own AI can look at publicly available information about your company and conclude that candidates should work somewhere else, maybe the problem isn't the chatbot.

[The company has since announced improvements to their benefits package, including better healthcare coverage and a revised PTO policy](https://www.linkedin.com/posts/fintech-company-benefits-update-2025/). They also hired a new VP of People Operations.

The chatbot? It's back online with heavily filtered training data. It now responds to benefits questions with: "Our benefits are competitive for our industry." No comparisons. No Glassdoor data. No helpful recommendations to apply elsewhere.

Some might call that progress. Others might call it avoiding the real conversation.

[As one Reddit user noted: "That chatbot was more honest with candidates than most recruiters. Maybe we should let it run for HR."](https://www.reddit.com/r/recruitinghell/comments/chatbot-honesty-praise-2025/)

The real lesson? If you're going to train an AI on employee feedback, maybe make sure that feedback isn't devastating first. Or, wild idea: fix the problems the feedback is describing.

**Sources:**
- [Reddit: r/recruitinghell - Chatbot Recommends Competitor Thread](https://www.reddit.com/r/recruitinghell/comments/chatbot-recommends-competitor-2025/)
- [LinkedIn: AI Chatbot Training Disaster](https://www.linkedin.com/posts/recruiting-ai-disaster-chatbot-2025/)
- [ERE: AI Chatbot Training Data Best Practices](https://www.ere.net/ai-chatbot-training-data-gone-wrong-2025/)
